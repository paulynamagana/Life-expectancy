{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow\timport keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"admissions_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>316.472000</td>\n",
       "      <td>107.192000</td>\n",
       "      <td>3.114000</td>\n",
       "      <td>3.374000</td>\n",
       "      <td>3.48400</td>\n",
       "      <td>8.576440</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.72174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>144.481833</td>\n",
       "      <td>11.295148</td>\n",
       "      <td>6.081868</td>\n",
       "      <td>1.143512</td>\n",
       "      <td>0.991004</td>\n",
       "      <td>0.92545</td>\n",
       "      <td>0.604813</td>\n",
       "      <td>0.496884</td>\n",
       "      <td>0.14114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.34000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>125.750000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>8.127500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>250.500000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>8.560000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.72000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>375.250000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.82000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>9.920000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.97000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Serial No.   GRE Score  TOEFL Score  University Rating         SOP  \\\n",
       "count  500.000000  500.000000   500.000000         500.000000  500.000000   \n",
       "mean   250.500000  316.472000   107.192000           3.114000    3.374000   \n",
       "std    144.481833   11.295148     6.081868           1.143512    0.991004   \n",
       "min      1.000000  290.000000    92.000000           1.000000    1.000000   \n",
       "25%    125.750000  308.000000   103.000000           2.000000    2.500000   \n",
       "50%    250.500000  317.000000   107.000000           3.000000    3.500000   \n",
       "75%    375.250000  325.000000   112.000000           4.000000    4.000000   \n",
       "max    500.000000  340.000000   120.000000           5.000000    5.000000   \n",
       "\n",
       "            LOR         CGPA    Research  Chance of Admit   \n",
       "count  500.00000  500.000000  500.000000         500.00000  \n",
       "mean     3.48400    8.576440    0.560000           0.72174  \n",
       "std      0.92545    0.604813    0.496884           0.14114  \n",
       "min      1.00000    6.800000    0.000000           0.34000  \n",
       "25%      3.00000    8.127500    0.000000           0.63000  \n",
       "50%      3.50000    8.560000    1.000000           0.72000  \n",
       "75%      4.00000    9.040000    1.000000           0.82000  \n",
       "max      5.00000    9.920000    1.000000           0.97000  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has different scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.iloc[:,-1]\n",
    "features = df.iloc[:, 1:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.25, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "features_train_scale = sc.fit_transform(features_train)\n",
    "features_test_scale = sc.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-05 17:12:27.105629: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name=\"admission_model\")\n",
    "num_features = features_train.shape[1]\n",
    "input = layers.InputLayer(input_shape=(num_features,))\n",
    "model.add(input)\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=0.01)\n",
    "model.compile(loss= \"mse\", metrics=[\"mae\"], optimizer = opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 1s 14ms/step - loss: 0.1203 - mae: 0.2007 - val_loss: 0.6050 - val_mae: 0.4856\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0998 - mae: 0.1559 - val_loss: 0.0061 - val_mae: 0.0583\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0586 - val_loss: 0.0040 - val_mae: 0.0472\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0061 - mae: 0.0590 - val_loss: 0.0038 - val_mae: 0.0458\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0524 - val_loss: 0.0037 - val_mae: 0.0446\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0516 - val_loss: 0.0033 - val_mae: 0.0420\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0490 - val_loss: 0.0030 - val_mae: 0.0396\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0495 - val_loss: 0.0036 - val_mae: 0.0424\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0472 - val_loss: 0.0028 - val_mae: 0.0385\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0450 - val_loss: 0.0027 - val_mae: 0.0376\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0449 - val_loss: 0.0025 - val_mae: 0.0368\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0432 - val_loss: 0.0027 - val_mae: 0.0385\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0449 - val_loss: 0.0026 - val_mae: 0.0381\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0035 - mae: 0.0420 - val_loss: 0.0031 - val_mae: 0.0399\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0034 - mae: 0.0428 - val_loss: 0.0028 - val_mae: 0.0383\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0036 - mae: 0.0420 - val_loss: 0.0027 - val_mae: 0.0393\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0026 - val_mae: 0.0377\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0032 - mae: 0.0412 - val_loss: 0.0027 - val_mae: 0.0374\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0033 - mae: 0.0415 - val_loss: 0.0028 - val_mae: 0.0382\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0032 - mae: 0.0407 - val_loss: 0.0026 - val_mae: 0.0378\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0033 - mae: 0.0406 - val_loss: 0.0029 - val_mae: 0.0387\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0034 - mae: 0.0417 - val_loss: 0.0027 - val_mae: 0.0377\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0032 - mae: 0.0406 - val_loss: 0.0027 - val_mae: 0.0381\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0033 - mae: 0.0399 - val_loss: 0.0029 - val_mae: 0.0395\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0033 - mae: 0.0430 - val_loss: 0.0029 - val_mae: 0.0382\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0402 - val_loss: 0.0029 - val_mae: 0.0384\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0032 - mae: 0.0417 - val_loss: 0.0031 - val_mae: 0.0402\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0034 - mae: 0.0409 - val_loss: 0.0028 - val_mae: 0.0382\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0030 - mae: 0.0388 - val_loss: 0.0028 - val_mae: 0.0393\n",
      "Epoch 30/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0030 - mae: 0.0401 - val_loss: 0.0034 - val_mae: 0.0412\n",
      "Epoch 31/100\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0031 - mae: 0.0392 - val_loss: 0.0027 - val_mae: 0.0382\n",
      "Epoch 32/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0031 - val_mae: 0.0407\n",
      "Epoch 33/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0029 - mae: 0.0393 - val_loss: 0.0029 - val_mae: 0.0392\n",
      "Epoch 34/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0031 - mae: 0.0404 - val_loss: 0.0034 - val_mae: 0.0414\n",
      "Epoch 35/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0389 - val_loss: 0.0028 - val_mae: 0.0382\n",
      "Epoch 36/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0379 - val_loss: 0.0031 - val_mae: 0.0398\n",
      "Epoch 37/100\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 0.0030 - mae: 0.0390 - val_loss: 0.0030 - val_mae: 0.0418\n",
      "Epoch 38/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0029 - mae: 0.0395 - val_loss: 0.0030 - val_mae: 0.0416\n",
      "Epoch 39/100\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0030 - mae: 0.0390 - val_loss: 0.0045 - val_mae: 0.0472\n",
      "Epoch 40/100\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0032 - mae: 0.0403 - val_loss: 0.0029 - val_mae: 0.0382\n",
      "Epoch 41/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0029 - mae: 0.0389 - val_loss: 0.0031 - val_mae: 0.0395\n",
      "Epoch 42/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0391 - val_loss: 0.0030 - val_mae: 0.0393\n",
      "Epoch 43/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0028 - mae: 0.0388 - val_loss: 0.0034 - val_mae: 0.0414\n",
      "Epoch 44/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0027 - mae: 0.0375 - val_loss: 0.0031 - val_mae: 0.0397\n",
      "Epoch 45/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0393 - val_loss: 0.0035 - val_mae: 0.0422\n",
      "Epoch 46/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0030 - mae: 0.0400 - val_loss: 0.0032 - val_mae: 0.0402\n",
      "Epoch 47/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0033 - mae: 0.0410 - val_loss: 0.0037 - val_mae: 0.0433\n",
      "Epoch 48/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0490 - val_loss: 0.0031 - val_mae: 0.0396\n",
      "Epoch 49/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0416 - val_loss: 0.0030 - val_mae: 0.0390\n",
      "Epoch 50/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0392 - val_loss: 0.0031 - val_mae: 0.0410\n",
      "Epoch 51/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0458 - val_loss: 0.0034 - val_mae: 0.0419\n",
      "Epoch 52/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0036 - mae: 0.0433 - val_loss: 0.0030 - val_mae: 0.0403\n",
      "Epoch 53/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0032 - mae: 0.0427 - val_loss: 0.0031 - val_mae: 0.0407\n",
      "Epoch 54/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0432 - val_loss: 0.0034 - val_mae: 0.0436\n",
      "Epoch 55/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0034 - mae: 0.0436 - val_loss: 0.0032 - val_mae: 0.0404\n",
      "Epoch 56/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0031 - mae: 0.0411 - val_loss: 0.0034 - val_mae: 0.0403\n",
      "Epoch 57/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0029 - mae: 0.0386 - val_loss: 0.0030 - val_mae: 0.0384\n",
      "Epoch 58/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0031 - mae: 0.0405 - val_loss: 0.0036 - val_mae: 0.0430\n",
      "Epoch 59/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0028 - mae: 0.0382 - val_loss: 0.0031 - val_mae: 0.0401\n",
      "Epoch 60/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0030 - mae: 0.0397 - val_loss: 0.0043 - val_mae: 0.0457\n",
      "Epoch 61/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0031 - mae: 0.0396 - val_loss: 0.0032 - val_mae: 0.0402\n",
      "Epoch 62/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0027 - mae: 0.0371 - val_loss: 0.0033 - val_mae: 0.0400\n",
      "Epoch 63/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0388 - val_loss: 0.0036 - val_mae: 0.0422\n",
      "Epoch 64/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0029 - mae: 0.0383 - val_loss: 0.0032 - val_mae: 0.0402\n",
      "Epoch 65/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0031 - mae: 0.0416 - val_loss: 0.0034 - val_mae: 0.0415\n",
      "Epoch 66/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0031 - mae: 0.0402 - val_loss: 0.0032 - val_mae: 0.0402\n",
      "Epoch 67/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0027 - mae: 0.0383 - val_loss: 0.0032 - val_mae: 0.0400\n",
      "Epoch 68/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0026 - mae: 0.0367 - val_loss: 0.0031 - val_mae: 0.0395\n",
      "Epoch 69/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0027 - mae: 0.0375 - val_loss: 0.0041 - val_mae: 0.0455\n",
      "Epoch 70/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0027 - mae: 0.0380 - val_loss: 0.0036 - val_mae: 0.0422\n",
      "Epoch 71/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0422 - val_loss: 0.0041 - val_mae: 0.0452\n",
      "Epoch 72/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0402 - val_loss: 0.0045 - val_mae: 0.0516\n",
      "Epoch 73/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0031 - mae: 0.0404 - val_loss: 0.0035 - val_mae: 0.0430\n",
      "Epoch 74/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0425 - val_loss: 0.0033 - val_mae: 0.0415\n",
      "Epoch 75/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0499 - val_loss: 0.0035 - val_mae: 0.0423\n",
      "Epoch 76/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0035 - mae: 0.0436 - val_loss: 0.0033 - val_mae: 0.0408\n",
      "Epoch 77/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0028 - mae: 0.0375 - val_loss: 0.0030 - val_mae: 0.0405\n",
      "Epoch 78/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0030 - mae: 0.0389 - val_loss: 0.0040 - val_mae: 0.0442\n",
      "Epoch 79/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0035 - mae: 0.0421 - val_loss: 0.0036 - val_mae: 0.0452\n",
      "Epoch 80/100\n",
      "36/36 [==============================] - 0s 14ms/step - loss: 0.0028 - mae: 0.0393 - val_loss: 0.0030 - val_mae: 0.0396\n",
      "Epoch 81/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0028 - mae: 0.0375 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 82/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0027 - mae: 0.0386 - val_loss: 0.0037 - val_mae: 0.0459\n",
      "Epoch 83/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0386 - val_loss: 0.0033 - val_mae: 0.0416\n",
      "Epoch 84/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0456 - val_loss: 0.0033 - val_mae: 0.0422\n",
      "Epoch 85/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0031 - mae: 0.0417 - val_loss: 0.0026 - val_mae: 0.0374\n",
      "Epoch 86/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0028 - mae: 0.0381 - val_loss: 0.0030 - val_mae: 0.0395\n",
      "Epoch 87/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0029 - mae: 0.0388 - val_loss: 0.0028 - val_mae: 0.0378\n",
      "Epoch 88/100\n",
      "36/36 [==============================] - 0s 11ms/step - loss: 0.0027 - mae: 0.0375 - val_loss: 0.0026 - val_mae: 0.0359\n",
      "Epoch 89/100\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.0029 - mae: 0.0391 - val_loss: 0.0029 - val_mae: 0.0389\n",
      "Epoch 90/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0379 - val_loss: 0.0030 - val_mae: 0.0390\n",
      "Epoch 91/100\n",
      "36/36 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0439 - val_loss: 0.0029 - val_mae: 0.0376\n",
      "Epoch 92/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0450 - val_loss: 0.0029 - val_mae: 0.0385\n",
      "Epoch 93/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0404 - val_loss: 0.0030 - val_mae: 0.0394\n",
      "Epoch 94/100\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 0.0031 - mae: 0.0409 - val_loss: 0.0030 - val_mae: 0.0397\n",
      "Epoch 95/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0030 - mae: 0.0402 - val_loss: 0.0031 - val_mae: 0.0392\n",
      "Epoch 96/100\n",
      "36/36 [==============================] - 1s 17ms/step - loss: 0.0028 - mae: 0.0363 - val_loss: 0.0038 - val_mae: 0.0474\n",
      "Epoch 97/100\n",
      "36/36 [==============================] - 0s 10ms/step - loss: 0.0028 - mae: 0.0399 - val_loss: 0.0031 - val_mae: 0.0396\n",
      "Epoch 98/100\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0417 - val_loss: 0.0032 - val_mae: 0.0411\n",
      "Epoch 99/100\n",
      "36/36 [==============================] - 0s 9ms/step - loss: 0.0034 - mae: 0.0423 - val_loss: 0.0036 - val_mae: 0.0461\n",
      "Epoch 100/100\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0462 - val_loss: 0.0049 - val_mae: 0.0532\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(features_train_scale, labels_train.to_numpy(), epochs=100, batch_size=8, verbose=1, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  9.661518096923828\n",
      "MAE:  93.45478057861328\n"
     ]
    }
   ],
   "source": [
    "ad_mse, ad_mae = model.evaluate(features_test, labels_test, verbose=0)\n",
    "print(\"MAE: \", ad_mae)\n",
    "print(\"MAE: \", ad_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(2, 1, 1)\n",
    "ax1.plot(history.history['mae'])\n",
    "ax1.plot(history.history['val_mae'])\n",
    "ax1.set_title('model mae')\n",
    "ax1.set_ylabel('MAE')\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.legend(['train', 'validation'], loc='upper left')\n",
    " \n",
    "  # Plot loss and val_loss over each epoch\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_title('model loss')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# used to keep plots from overlapping each other  \n",
    "fig.tight_layout()\n",
    "fig.savefig('my_plots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.002567366407109306\n"
     ]
    }
   ],
   "source": [
    "predicted_values = model.predict(features_test) \n",
    "print(r2_score(labels_test, predicted_values)) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
